
		
\chapter{Co-primality, continued fractions, and M\"obius maps}
\abstract{%
	It would be wise to skip, or read very glancingly, this chapter on a first reading. 
	The material on co-prime integers and B\'ezout relations is  only needed for those who want to closely follow the proofs of Chapter~\ref{ch:cylinder}. M\"obius maps are the main language of  the renormalisation approach to the van Iterson diagram discussed at the end of Chapter~\ref{ch:classifying}, but are not at all essential to understand the biological implications of the mathematics.  The details of the matrix form of the Euclidean algorithm may only matter to those curious about the relationships between Fibonacci phyllotaxis and Escher prints.
}




\section{B\'ezout relations}
\index{co-prime integers!B\'ezout relation}
The previous chapter defined co-primality for a pair of integers. An equivalent condition is the existence of a  B\'ezout relation: the integer pair $(u,v)$ satisfies the B\'ezout relation for the non-negative integer pair $(m,n)$ iff
\begin{align}
	|n  u-mv| = 1.
\end{align}
or euqivalently as a matrix determinant:
\begin{align}
	\det \begin{pmatrix} n& v \\ m & u \end{pmatrix} = \pm 1.
\end{align}
So $(3,4)$ are a B\'ezout pair for $(8,11)$. 
If $u$ and $v$ exist then they are a certificate of co-primality: we will see below that $(m,n)$ can satisfy  $ n  u - m v= g$ iff $|g|$ is the greatest common factor of $m$ and $n$. They are not unique because if $(u,v)$ satisfies the B\'ezout relation then so does $(u+km,v+kn)$ for any integer $k$: $(11,15)$ is also a B\'ezout pair for $(8,11)$. We can introduce a range condition by picking a particular $k$ which can be used to enforce $0\leq v< n$, but there is still a further ambiguity because if
$n u- m v  =+1$ provides one solution, then $n(m-u)-m(n-v)=-1$ provides another: because $11\times3-4\times8 =+1$ we can find $11\times 1-4\times 3=-1$. 

\section{The winding-number pair}
\index{co-prime integers!winding-number pair}
\label{sec:wnp}
There are different ways to cope with the non-uniqueness of  B\'ezout pairs.
Here we pick out a particular pair, the \textit{winding-number pair}. 
For co-prime integers  $(m,n)$, the winding-number pair is the unique pair  $(u,v)$ which satisfies the B\'ezout relation $|n  u-mv| = 1$ and also
\begin{align}
	0\leq \frac{u+v}{m+n}\leq \frac{1}{2}. \label{eq:wnpFarey}
\end{align}
There are a handful of special cases: in this book the winding-number pair for  $(0,1)$ is by definition $(1,0)$, for $(1,0)$ is $(0,1)$, and for $(1,1)$ is $(1,0)$. 
As we will see below, half of the time the winding-number pair will yield $nu-mv=+1$ and half the time $n u-m v=-1$. We could alternatively have found a unique pair by insisting on a particular choice of sign $nu-mv=+1$, but in this way there is a clear connection to the signs of the $\Delta$s that will pepper Chapter~\ref{ch:cylinder}.



\begin{jExercise}\label{ex:wnp}
	Compute the winding-number pair for $(m,n)$ for co-prime $m,n$ less than 10. 
\end{jExercise}
\begin{jAnswer}{ex:wnp}{
	Some winding-number pairs are given in Table~\ref{tab:wnp2}.
	\begin{table}
	\caption{Winding number pairs given as Farey intervals $[u/m,v/n]$. For $m$ and $n$ positive and distinct these are all contained in $[0,\jhalf]$ but the natural order of the endpoints varies with the sign of $mv-nu=\pm 1$.}
\label{tab:wnp2}
	\begin{equation*}
		\begin{array}{lllll}
			\hline
			\\
			\jFarey{u}{m}{v}{n}
			&\jFarey{0}{1}{1}{0}&   &  &   \\[2ex]
			\jFarey{ 1}{0}{0}{1} &  \jFarey{1}{1}{0}{1}  &  \jFarey{1}{2}{0}{1}  & \jFarey{1}{3}{0}{1}& \jFarey{1}{4}{0}{1} \\[2ex]
			&  \jFarey{0}{1}{1}{2}&  & \jFarey{1}{3}{1}{2} &  \\
			&  \jFarey{0}{1}{1}{3} & \jFarey{1}{2}{1}{3} &  & \jFarey{1}{4}{1}{3} \\[2ex]
			&  \jFarey{0}{1}{1}{4} &  & \jFarey{1}{3}{1}{4} & \\[2ex]
			&  \jFarey{0}{1}{1}{5} &\jFarey{1}{2}{2}{5} & \jFarey{1}{3}{2}{5} &\jFarey{1}{4}{1}{5} \\[2ex]
			&  \jFarey{0}{1}{1}{6} &  &  &  \\
			&  \jFarey{0}{1}{1}{7} &\jFarey{1}{2}{3}{7}& \jFarey{1}{3}{2}{7} & \jFarey{1}{4}{2}{7}  \\[2ex]
			&  \jFarey{0}{1}{1}{8} &  & \jFarey{1}{3}{3}{8} &  \\[2ex]
			&  \jFarey{0}{1}{1}{9} & \jFarey{1}{2}{4}{9} &  & \jFarey{1}{4}{2}{9}  \\[2ex]
			\hline
		\end{array}
	\end{equation*}
		\end{table}
}\end{jAnswer}
Chapter~\ref{ch:cylinder} will also reveal the reason for the name `winding-number pair'. 
For the small integers in plant spiral counts it is perfectly feasible to compute highest common factors and winding-number pairs by exhaustive search. But nevertheless the rest of this Chapter shows how an algorithmic approach sheds a light on the structure of co-prime pairs and their winding-numbers in a way that has been helpful in the past to mathematicians puzzling over Fibonacci structure. 


\section{Euclid's algorithm}
\index{Euclidean algorithm}
\label{sec:euclid}
Euclid's algorithm finds the highest common divisor of two positive integers by repeatedly subtracting the smaller as many times as we can from the larger to find a new, smaller pair of integers,  stopping when one of them is zero. It is  simple to implement, and tracking the variables in the intermediate steps of the algorithm will allow us to understand connections with continued fractions and structure of the van Iterson diagram of Chapter~\ref{ch:cylinder}.
For example, consider calculating the highest common factor of $4$ and $11$:
\begin{align}
	11 - {\jHeadingColour 2}\times 4 & = 3 
	\\
	4 - {\jHeadingColour 1}\times 3 & = 1\label{eq:411}
	\\
	3 - {\jHeadingColour 3}\times 1 & = 0 
\end{align}
%
This works by successively answering the question of how many times 4 goes into 11 (ie ${\jHeadingColour 2}$), 3 into 4  (${\jHeadingColour 1}$), and 1 into 3 (${\jHeadingColour 1}$) and generates 
a particular sequence of what we will call  $\jqi={\jHeadingColour 2, 1, 3}$ which shows the co-primality of 4 and 11. Because of the central role of the $\jqi$ they are coloured in red in what follows. It is possible to use this decomposition to compute the winding-number pair, which we can see if we rewrite the algorithm in more formally. 
Given integers $n\geq m>0$  we set $r_{-1}=n$, $r_0=m$ and $i=0$:
\begin{enumerate}
	\item Set an integer $\jqi=\lfloor r_{i-1}/r_i \rfloor $, to non-negatively minimise $r_{i-1}-q r_{i}$ 
	\item  Set  $r_{i+1}=r_{i-1}-\jqi r_{i}$. 
	\item If $r_{i+1}=0$, set $N=i$ and terminate.
	\item Otherwise increment $i$, and repeat.
\end{enumerate}
\begin{theorem}
	Euclid's algorithm terminates with the greatest common factor $GCF(m,n)$:
	\begin{eqnarray}
		r_N =  
		GCF(m,n) 
	\end{eqnarray}
\end{theorem}
\begin{proof}
	The $r_i$ are a strictly decreasing sequence of positive integers and so the algorithm always terminates. Suppose the $GCF$ is $k$. Now $k$ divides $r_0$, $k|r_0$, and the $i$-th step of the iteration preserves the fact that  $k|r_i$,  and so in particular $k|r_N$. Now $r_N|r_{N-1}$ and the iteration step also shows that if $r_N|r_i$ and $r_N|r_{i-1}$ then $r_N|r_{i-2}$, and so following the $r_i$s in reverse order we see $r_N$ divides all of them and divides both $m$ and $n$.  So $r_N$ is a common divisor and so $r_N\leq k$ but since $k|r_N$, $r_N=k$. 
\end{proof}

\subsection{Matrix form of the Euclidean algorithm}
\index{Euclidean algorithm!matrix form}
\mmafig{Txb0301EuclideanTree}{Computing the highest common factor of 4 and 11 by successive matrix reductions upwards to the identity matrix. Conversely, the extended tree downwards from the identity matrix, branching by an $E$ or an $ES$ matrix-multiplication at each node after the second, will contain every pair of co-prime integers, in the first column of each matrix, with the corresponding winding-number pair in the second column. 
The $\jqi$s of the Euclidean reduction emerge as the number of $E$s between each $S$. The horizontal order of the $E$ and $ES$ branches below each matrices is chosen so that the child matrices are ordered by their Farey mediant as defined in section~\ref{sec:farey}. Chapter~\ref{ch:classifying} will reflect on the close similarity between this diagram than the van Iterson classification.}{1}
%
We can solve the B\'ezout relation by putting  Euclid's algorithm in matrix form. For example
the first reduction of~\eqref{eq:411} is
\begin{align*}
\begin{pmatrix} 11 \\ 4 \end{pmatrix}  &= \begin{pmatrix} 1 & \jqn{2} \\ 0 & 1\end{pmatrix} \begin{pmatrix} 3 \\ 4\end{pmatrix} 
\\
&
= \begin{pmatrix} 1 &1 \\ 0 & 1\end{pmatrix}^{\jqn{2}}  \begin{pmatrix} 0 & 1  \\ 1 & 0  \end{pmatrix} \begin{pmatrix} 4 \\ 3 \end{pmatrix}
\\
&=
E^{\jqn{2}} S \begin{pmatrix} 4 \\ 3 \end{pmatrix}
\end{align*}
where we have defined matrices  $E$ corresponding to a  `Euclidean' reductions and $S$ corresponding to `swap' of the integer pair. Matrix algebra shows $E^\jq$ has a $q$ in the upper-right corner:
\begin{align*}
	E^{\jq} &=  \begin{pmatrix} 1 & \jq \\ 0 & 1\end{pmatrix}
	;
	S =  \begin{pmatrix} 0 & 1  \\ 1 & 0  \end{pmatrix}
	;
	E^{\jq} \cdot S = \begin{pmatrix}\jq & 1  \\ 1 & 0  \end{pmatrix}
\end{align*}
Moreover  $\det E=1$ and $\det S=-1$ and so the matrix of any product of $E$s and $S$s has determinant of modulus 1. 

After we learn the $\jq$ sequence through the Euclidean algorithm we can write the result in matrix form as 
\begin{align*}
	\begin{pmatrix} 11 \\ 4 \end{pmatrix}  &= 
	(E^{\jqn{2}} S )\cdot( E^{\jqn{1}} S ) \cdot (E^{\jqn{3}} S)  \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
\end{align*}
If we apply the same series of transformations to the column vector $(0,1)$ we will obtain a column vector of the form $(v,u)$  so that
\begin{align}
		M_{\jqn{2}\jqn{1}\jqn{3}}= \begin{pmatrix} 11 & v \\ 4 & u \end{pmatrix}   &= 
	(E^{\jqn{2}} S )\cdot( E^{\jqn{1}} S ) \cdot (E^{\jqn{3}} S) 
	 \begin{pmatrix} 1&0  \\ 0&1 \end{pmatrix} 
	 \label{eq:M213}.
\end{align}
This shows there is a  $u$ and $v$ which satisfy $|4 v-11 u|=1$ and give us a B\'ezout relation, and since $\det E=1$ but $\det S=-1$, the sign of the determinant of $M$ is determined by how many $S$ matrices appear in the product. It also provides a way to calculate $u$ and $v$:
\begin{align*}
	M_{\jqn{2}\jqn{1}\jqn{3}}&=
	 \begin{pmatrix} 2 & 1 \\ 1 & 0 \end{pmatrix}\cdot
 \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}\cdot
	  \begin{pmatrix} 3 & 1 \\ 1 & 0 \end{pmatrix}
	 	 \\
	 &= \begin{pmatrix} 11 & 3 \\ 4 & 1 \end{pmatrix}
% \label{eq:M213value}.
\end{align*}
For a general $m$ and $n$, using the $\jqi$ values from the Euclidean algorithm gives us 
\begin{align}
	M_{\jqn{q_1}\jqn{q_2}\cdots\jqn{q_N}}=\begin{pmatrix} n & v \\ m & u \end{pmatrix}   &= 
	(E^{\jqn{q_1}} S )\cdot( E^{\jqn{q_2}} S ) \cdots  (E^{\jqn{q_N}} S)  \begin{pmatrix} 1&0  \\ 0&1 \end{pmatrix}.
	\label{eq:EuclideanMatrixq}
\end{align}
%Dropping the $\jq$s now, we will 
%\begin{align}
%	M_{nm} &=\begin{pmatrix} n & v \\ m & u \end{pmatrix} 
%	\\
%	\Delta_{nm} &= \det 	M_{nm}
%	\\
%	|\Delta_{nm}| &= 1
% 	\label{eq:EuclideanMatrix}
%\end{align}

Because every pair of co-prime integers has a unique $\jqi$ sequence, every pair such pair will appear exactly once in the first column of a matrix in the tree generated by continuing Figure~\ref{fig:Txb0301EuclideanTree} downwards.
The second column is the corresponding B\'ezout pair. The same algorithm also works when $m$ and $n$ are not co-prime:
\begin{jExercise}\label{ex:showk}
	Show that if $m$ and $n$ have highest common factor $g$ then $u,v$ found in this way give $|nu-mv|=g$.
\end{jExercise}
\begin{jAnswer}{ex:showk}{
	Multiply~\eqref{eq:EuclideanMatrixq} by $g$.
}\end{jAnswer}
As we will see in the next section, this B\'ezout pair is in fact the winding-number pair.

\begin{jExercise}\label{ex:f1}
	Show that for $j>1$ the  $\jqi$ for the Fibonacci pair $F_{j+1}$ and $F_j$ are a sequence of 1s of length $j$ and 
	the pair have a B\'ezout pair, but not a winding-number pair,  $F_j$ and $F_{j-1}$.
\end{jExercise}
\begin{jAnswer}{ex:f1}{
		It is easy to show by induction that 
\begin{align}
	\begin{pmatrix} 
		F_{j+1} & F_{j} 
		\\
		F _j & F_{j-1}
	\end{pmatrix} &= 	(E^\jqn{1} S)^{j}.
	\label{eq:FibonacciMatrixB}
\end{align}
So the  $\jqi$'s are all \jqn{1} and the determinant shows that $(F_{j},F_{j-1})$ is a B\'ezout pair. It is not a winding-number pair because $F_{j-1}/F_j>\jhalf$. Note these are not the matrices that appear in Figure~\ref{fig:Txb0301EuclideanTree}.
}\end{jAnswer}

For those comfortable thinking of vector spaces,  we might think of any pair of co-prime integers as a basis pair for the space of integers.  Given a co-prime pair $m$ and $n$, every integer can be expressed as a sum $n (k u)+ m (-k v)$.  From this perspective the Euclidean algorithm  can  be seen as a series of changes of these bases.  The individual $E^{\jqi}$ matrices correspond to the change of base at each step, the product matrix is the change of basis between $m,n$ and $k,1$, and the $ |mv - nu|=k$ relationship tells us about how areas are scaled in the different bases. 

\section{Farey trees and winding-number pairs}
\label{sec:farey}
Thanks to a careful choice of stopping rule for the algorithm, or equivalently because of how we pruned the tree of Figure~\ref{fig:Txb0301EuclideanTree} not to bifurcate from the first two nodes, the $(u,v)$ which emerge from the Euclidean algorithm are not just a pair satisfying the B\'ezout relation but they are exactly the winding-number pair.
%
Each matrix in the tree of Figure~\ref{fig:Txb0301EuclideanTree} is of the form
\begin{align*}
	\begin{pmatrix} 
		n & v
		\\
		m & u
	\end{pmatrix}
\end{align*}
with $nu-mv=\Delta$ and $|\Delta|=1$. For each matrix below the root, we can form two rationals $u/m$ and $v/n$; for  $\Delta=1$, $u/m>v/n$ while for $\Delta=-1$, $u/m<v/n$ but in either case they form the endpoints of a real interval we will call the Farey interval for the matrix. 
The Farey interval of the integers $m, n, u, v$ is $[u/m,v/n]$ although the endpoints may not be in order. 
The Farey sum of these two rational endpoints, or the Farey mediant of the matrix, is $(u+v)/(m+n)$ which is always contained in the Farey interval.
\begin{jExercise}\label{ex:farey}
	Show this.
\end{jExercise}
\begin{jAnswer}{ex:farey}{
	Compute the difference between the Farey sum and the endpoints: the signs of these and the difference between the endpoints are all controlled by the sign of~$\Delta$. 
}
\end{jAnswer}

Farey intervals for the first few matrices in the tree are shown in Figure~\ref{fig:Txb0302FareyIntervals}.%
\mmafig{Txb0302FareyIntervals}{Farey intervals $[u/m,v/n]$ for matrices $\begin{pmatrix}
		n & m\\ v & u
\end{pmatrix}
$ coloured blue if the determinant of the matrix is $+1$ and white when it is $-1$.
}{1}%
%
If a matrix has a Farey interval of  $[u/m,v/n]$, then multiplication by $E$ gives a new matrix with a Farey interval of $[u/m,(u+m)/(v+n)]$ and multiplication by $ES$ gives one of  $[v/n,(u+m)/(v+n)]$: the interval splits at the Farey sum at each bifurcation. Since the matrix one down from the root has a Farey interval of $[0,\jhalf]$, every matrix below that has its Farey interval within this range, which means that  B\'ezout pair in the second column of each matrix is in fact a winding-number pair.

 Examining the tree also justifies our claim that $m v-nu$ is plus or minus one equally often in the tree (save for the first two nodes), since its sign changes each time there is a multiplication by $ES$ rather than $S$.


\subsection{Fibonacci pairs}
\label{sec:euclidean}
The Fibonacci matrices in Figure~\ref{fig:Txb0301EuclideanTree} are found by consistently choosing the $ES$ branch for each bifurcation from the second node so that, for example
\begin{align*}
	\begin{pmatrix} 
	13 & 5 
		\\
		8 & 3
	\end{pmatrix} &= 	(E S)^{{4}} \cdot E^2 S ;
\end{align*}
and recalling that $F_{7}=13$, this generalises easily to
\begin{align}
	\begin{pmatrix} 
		F_{j+1} & F_{j-1} 
		\\
		F _j & F_{j-2}
	\end{pmatrix} &= 	(E S)^{{j-4}} \cdot E^2 S.
\label{eq:FibonacciMatrix}
\end{align}
%
\begin{jExercise}\label{ex:fpairs}
	Prove this.
\end{jExercise}
%
\begin{jAnswer}{ex:fpairs}{
\begin{align}
E S \begin{pmatrix} 	F_{j+1} & F_{j-1} 	\\	F _j & F_{j-2}\end{pmatrix}
  &= 	\begin{pmatrix} 1 & 1\\1 & 0 \end{pmatrix}
\begin{pmatrix} F_{j+1} & F_{j-1} \\F _j & F_{j-2}\end{pmatrix}
&= 
\begin{pmatrix} 	F_{j+2} & F_{j+1} 	\\	F _{j+2} & F_{j-1}
\end{pmatrix}
\end{align}
}\end{jAnswer}
%
Together with the previous section this shows that the winding-numbers for a pair of adjacent Fibonacci numbers are the two previous Fibonacci numbers.
Moreover we can calculate the associated Farey intervals for use in Chapter~\ref{ch:cylinder}.


\begin{jExercise}\label{ex:fareyFpair}
	Show  the Farey interval for the Fibonacci pair $(m,n)= (F_j,F_{j+1})$ contains $1/\tau^2=1/(1+\tau)$ but that for $k>1$ the Farey interval for the generalised Fibonacci pair $(F^k_j,F^k_{j+1})$ contains $\tau/(1+ k \tau)$.
\end{jExercise}
\begin{jAnswer}{ex:fareyFpair}  {
For  $k=1$, the mediant of the Farey interval $(u+v)/(m+n)$ is $F_j/F_{j+2}$. 
Generalised Fibonacci number pairs, such as the Lucas numbers $F^3_4=7$ and $F^3_5=11$, also appear in Figure~\ref{fig:Txb0301EuclideanTree}. From inspection of the tree or by induction we have for $k>1$
\begin{align}
	\begin{pmatrix} 
		F^k_{j+1} & F_j 
		\\
		F^k_j & F_{j-1}
	\end{pmatrix} &= 	(E\cdot  S)^{j-1} \cdot  (E^k S) 
	\label{eq:GeneralizedFibonacciMatrix}
\end{align}
(This is still true for $k=1$ but as we have seen delivers a B\'ezout pair but not the winding-number pair). For these generalised pairs the Farey mediant is 
\begin{align}
	\frac{	 F_j + F_{j-1}}{F^k_{j+1}+F^k_{j}}&=	\frac{	 F_{j+1}}{F^k_{j+2}}
\\
	&= 	\frac{	 F_{j+1}}{F_{j} + k F_{j+1}}
		\\&= \frac{ F_{j+1}/F_{j}}{1+ k F_{j+1}/F_{j}}
\end{align}	
making use of the well-known relation $	F^k_{j+1} =   k F_j+ F_{j-1}$. Finally we use $\lim_{ k\tends \infty}  F_{j+1}/F_{j}=\tau$ together with the fact that the Farey intervals are nested.
}
\end{jAnswer}

\section{Continued fractions}

If we divide each line of the Euclidean algorithm example above by $r_i$ we get
\begin{align}
	\frac{11}{4} - {\jHeadingColour 2} & = \frac{3}{4}
	\\
	\frac{4}{3} - {\jHeadingColour 1} & = \frac{1}{3}
	\\
	\frac{3}{1} - {\jHeadingColour 3} & = 0 
\end{align}
In each case the right hand side fraction is the inverse of the first fraction on the next line and we can solve  in reverse order to get
\begin{align}
	\frac{1}{3} &=  \frac{1}{\jHeadingColour 3}
	\\
	\frac{3}{4} &=  \frac{1}{{\jHeadingColour 1}+ \frac{1}{\jHeadingColour 3}}
	\\
	\frac{11}{4} &=  {\jHeadingColour 2}+
		\frac{1}{{\jHeadingColour 1}+ \frac{1}{\jHeadingColour 3}}
\end{align}
So there is a close link between the Euclidean algorithm and the construction of continued fractions. 
The continued fraction
generated by the finite sequence $\jqix{0}\ldots \jqix{N} $ is by definition
\begin{align}
	[\jqix{0},\ldots  \jqix{N}] &= \jqix{0} +\cfrac{1}{\jqix{1}+\cdots \cfrac{\cdots}{\jqix{{N-1}}+\cfrac{1}{\jqix{N}}}}
\end{align}
When representing a continued fraction less than 1, $\jqix{0}$ will be zero, but otherwise typically the $\jqi$ are strictly positive integers. We can usefully relax this rule for the last coefficient:
\begin{align}
	\frac{11}{4} &=  	[\jqn{2},\jqn{1},\jqn{3}]
	\\
&= 	[\jqn{2},\jqn{1}+1/\jqn{3}].
\end{align}
The reason we have used the same label $\jq$ as in the Euclidean algorithm is that the integer $\jq_i$s that the Euclidean algorithm generates for the hcf of $m$ and $n$ are exactly the continued fraction coefficients of $n/m$. Specifically, to compute the continued fraction coefficients $\jqix{0}\ldots \jqix{N} $ of a real $d$ we set 
$\rho_{-1}=d$, $\rho_{0}=1$ and $i=0$ and then
\begin{enumerate}
	\item Set an integer $\jqi=\lfloor \rho_{i-1}/\rho_{i} \rfloor$
	\item Set $\rho_{i+1} = \rho_{i-1} - \jqi \rho_{i}$. 
	\item If $\rho_{i+1} =0$, set $N=i$ and terminate
	\item Otherwise increment $i$ and repeat
\end{enumerate}
This is  the same as Euclid's algorithm but for the scaled sequence member $\rho_i=r_i/r_{i+1}$. It will terminate if $d$ is rational $n/m$, because Euclid's algorithm does in that case, but it will not if $d$ is irrational. In either case the intermediate continued fractions generated at each stage represent increasingly good approximations to $d$. 

There is a large literature on continued fractions. Fowler~\cite{fowlerMathematicsPlatoAcademy1999} combines the basic results with a relevant historical perspective while Berger~\cite{bergerGeometryRevealedJacob2010} adds an informative geometric view. 

\section{Continued fractions and M\"obius maps}
\newcommand{\wC}{w}%late relabel
Using the continued-fraction representation, given a set of $\jqix{i}$s we can define a function of $\wC$ as
\begin{align}
	f_{\jqix{0}\ldots \jqix{i}}(\wC) &= [\jqix{0}\ldots \jqix{i}  , \wC] 
\end{align}
Taking coefficients from in our running example we  have 
\begin{align}
	\begin{split}
f_{\jqn{3}}&=  \jqn{3} + \frac{1}{\wC} = \frac{3 \wC+1}{\wC+0} 
\\
f_{\jqn{1},\jqn{3}}  &=  \jqn{1} + \frac{1}{\jqn{3}+1/\wC} = \frac{4 \wC+1}{3\wC+1} 
\\ 
f_{\jqn{2},\jqn{1},\jqn{3}}  &=  \jqn{2} + \frac{1}{\jqn{1}+\frac{1}{
		\jqn{3}+1/\wC}} = \frac{11 \wC+3}{4\wC+1} %\label{eq:frac411}.
	\end{split}\label{eq:fq}
\end{align}
where we recognise the coefficients of the matrix $M_{\jqn{2},\jqn{1},\jqn{3}}$ of equation~\ref{eq:M213} arising from the Euclidean algorithm for 11 and 4. Clearly this is not a co-incidence, and by analogy with the previous sections we can see that $f$ can be constructed by repeated function compositions moving us down the tree of Figure~\ref{fig:Txb0301EuclideanTree}. 
Indeed since $	f_{\jqix{i}}  =  \jqix{i} +1/{\wC}  $, the last two can be written as
\begin{align}	
	f_{\jqn{1},\jqn{3}}  &=  	f_{\jqn{1}}(	f_{\jqn{3}}(\wC)) = 	f_{\jqn{1}}\circ 	f_{\jqn{3}}
	\\	f_{\jqn{2},\jqn{1},\jqn{3}}  &=
	%  	f_{\jqn{2}}(	f_{\jqn{1}}(		f_{\jqn{3}}(\wC)))) =
	 f_{\jqn{2}}\circ 	f_{\jqn{1}} \circ 	f_{\jqn{3}}
\end{align}
and in general
\begin{align}
	f_{\jqix{0}\jqix{1}\cdots\jqix{N}} &= 	f_{\jqix{0}}\circ f_{\jqix{1}}\cdots\circ f_{\jqix{N}}
\end{align}
Each of the $f$ constructed in this way is a \textit{M\"obius map}.

\subsection{M\"obius maps}
\label{sec:moebiusdef}
M\"obius maps have the form\jNote{Poincar\'e called these Fuchsian functions; they have variously been called automorphic functions, Hilbert modular functions, affine transforms or fractional linear transformations.  I follow the authority of Wikipedia, partly because as a native English reader I see an umlaut as conferring scientific respectability.}

\begin{align}	f(\wC) &=  \frac{a \wC +b}{c \wC+ d},
\end{align}
and are associated with a coefficient matrix
\begin{align}
	M(f) &=
	\begin{bmatrix}
		a & b \\ c & d	\end{bmatrix}.
\end{align}
It can be verified directly that the composition of two M\"obius maps is a M\"obius map, and that the coefficient matrix of the composition is the conventional matrix product of the coefficient matrices:
\begin{align}
	M(f_1 \circ f_2) &= M(f_1 ) \cdot M( f_2)
\end{align}
One way to see this is to note that 
\begin{equation}
	f\left(\frac{\wC_1}{\wC_2}\right) =\frac{w_1}{w_2}  \mbox{ where } 	\begin{pmatrix}
		w_1 \\ w_2 
	\end{pmatrix} = 
	\begin{pmatrix}
		a & b \\ c & d
	\end{pmatrix} 
	\begin{pmatrix}
		\wC_1 \\ \wC_2
	\end{pmatrix}.
\end{equation}
Although we do conventional matrix multiplication to compute the function composition, the functions being composed are not the conventional linear transformations of the real plane  $\jR^2\rightarrow\jR^2$ allowing rotation, scaling and shear. M\"obius maps are better thought of as functions on the complex plane  $f:\jC\rightarrow\jC$.  
If $\wC$ is a complex variable, then because $f(\wC)=\wC+b$, $f(\wC)=a \wC$, and $f(\wC)=1/\wC$  represent translation, scaling, and inversion in the unit circle,  M\"obius maps correspond to transformations of the complex plane generated by these geometric tranformations. 

In our applications of M\"obius maps the coefficient matrix will always have integer entries and moreover have determinant $mv-nu=\pm 1$. Because every such matrix is invertible in integers the maps form a group which I call the modular group.%
\footnote{If Wikipedia remains the authority, then the modular group is instead the group of matrices with integer entries and determinant $+1$, and the group with determinants $\pm 1$ is  $PSL(2,\jZ)$; but the same authority also says this is called $SL(2,\jZ)$ by some authors.}
A comprehensive treatment of M\"obius transformations is Ford's \textit{Automorphic Functions}~\cite{fordAutomorphicFunctions1951}, but they reappear in many branches of modern mathematics. 
We don't rely on, but later Chapters will partially rediscover, some well known properties of the modular group. In the language of hyperbolic geometry, when the upper complex half-plane is given the hyperbolic metric, its geodesics are semi-circles (including vertical lines) on the horizontal axis, and the modular group is the symmetry group of these geodesics: $f$ will map axis semi-circles to axis semi-circles~\cite{katokFuchsianGroups1992,schwartzMostlySurfaces2011}. 

More practically, we can re-cast the computation of~\ref{eq:fq} as a matrix multiplication. Since 
\begin{align}
		f_\jqix{i}(\wC)  &=\frac{\jqix{i} \wC+1}{\wC+0}
\end{align}
the corresponding coefficient matrix is 
\begin{align}
	\begin{bmatrix}
	\jqix{i} & 1 \\ 1 & 0	\end{bmatrix}
	 &=E^{\jqix{i}}\cdot S.
\end{align}
Now the composition
\begin{align}
	f_{\jqix{0}\jqix{1}\cdots\jqix{N}} &= 	f_{\jqix{0}}\circ f_{\jqix{1}}\cdots\circ f_{\jqix{N}}
\end{align}
has a coefficient matrix which can be computed as a matrix product
\begin{align}
	M_{\jqn{q_1}\jqn{q_2}\cdots\jqn{q_N}}
  &= 
	(E^{\jqn{q_1}} S )\cdot( E^{\jqn{q_2}} S ) \cdots  (E^{\jqn{q_N}} S)  \begin{pmatrix} 1&0  \\ 0&1 \end{pmatrix}	=	\begin{bmatrix} n & v \\ m & u \end{bmatrix}, 
\end{align}
say, as in~\eqref{eq:EuclideanMatrixq}. Then 
\begin{align}
	f_{\jqix{0}\ldots \jqix{N}}(\wC) &= \frac{n\wC+v}{m\wC+u} 
\end{align}
showing that~\eqref{eq:fq} holds true in general. 

\section{Summary}
This excursion onto the nursery slopes of hyperbolic geometry and number theory has explored the structure of the Euclidean algorithm as illustrated in Figure~\ref{fig:Txb0301EuclideanTree}. In Chapter 4 we will see this structure reappear in the van Iterson diagram for cylindrical lattices. 

