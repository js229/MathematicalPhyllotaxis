

\chapter{Mathematical background}

 It would be wise to skip, or read very glancingly, this chapter on a first reading. It covers the mathematical background the book relies on, and not every reader will want to read it in detail. The sections up to and including the golden angle are straightforward for anyone likely to get anything out of this book; co-prime integers and B\'ezout relations are only needed for those who want to closely follow the proofs that follow, and the details of the matrix form of the Euclidean algorithm may only matter to those curious about the relationships between Fibonacci phyllotaxis and Escher prints.

\label{CH:0}
\label{ch:0}
\section{Fibonacci sequences}

The Fibonacci sequence $F_n$ has as its first two members  $F_0=0$, $F_1=1$ and every subsequent member is the sum of the previous two:  $F_{n+2}=F_{n+1}+F_{n}$. 
Although there is a substantial literature on Fibonacci and related sequences~\cite{vajdaFibonacciLucasNumbers2008} we really only need this simple sum property for the Standard Picture. 
A related sequence is the Lucas sequence  ($1,3,4,7,11,\ldots$) with the same rule but different initial conditions, both Fibonacci and Lucas numbers are special cases of the generalised Fibonacci numbers with starting pair $F^k_1=1$, $F^k_2=k$. We will also encounter the sequence created by doubling each Fibonacci term, for which terminology varies but I'll call a double-Fibonacci sequence. 
%
\begin{table}[ht]
	\begin{center}
		\begin{tabular}{ll}
			\hline
			Fibonacci  &  $1,1,2,3,5,8,13,21,34,55,89,144,\ldots$ \Tstrut
			\\
			Double Fibonacci & $2,2,4,6,10,16,26,42,68,110,\ldots$
			\\
			Lucas ($F3$)&      $ 1,3,4,7,11,18,29,47,76,123,199\ldots$
			\\
			$F^4$  & $1,4,5,9,14,23,37,60,97,157\ldots$
			\\
			$F^5$ & $1,5,6,11,17,28,45,73,118,191\ldots$
			\\
			\ldots &
			\\
			$F^8$ & $1,8,9,17,26,43,69,112,181\ldots$
			\\
			\hline
		\end{tabular}
		\caption{Various sequences with Fibonacci structure}
		\label{tab:sequences}
	\end{center}
\end{table}
%

We might note that from Table~\ref{tab:sequences} that the Fibonacci, double Fibonacci and Lucas sequences together include all  of the first eleven integers except 9, so there is little remarkable about the observation that a particular system exhibits a structure including a low member of one of the sequences~\cite{cookeFibonacciNumbersReveal2006}. Finding pairs of adjacent members of the same series, or examples of numbers greater than ten, would be more significant.

\subsection{The golden ratio}
Starting the sequence with $F_0=0$, $F_1=1$, the general Fibonacci term is 
\begin{eqnarray}
F_n &=& \frac{\tau^n - (1-\tau)^n}{\sqrt{5}}
\end{eqnarray}
where $\tau$ is the golden ratio 
satisfying
\begin{eqnarray}
\tau^2 &=& \tau+1
\\
\tau &=& \frac{1+\sqrt{5}}{2} \approx 1.618
\\
&=& \lim_{n\rightarrow\infty} \frac{F_{n+1}}{F_n} 
\end{eqnarray}
Any sequence obeying the Fibonacci rule has $\tau$  as the limit of the ratio of its terms.

\subsection{The golden angle}
The golden angle is
\[
\Phi = \frac{2\pi}{\tau^2}  \approx 137^\circ
\]
so
\[
\frac{\Phi}{2 \pi} \approx \frac{F_{n}}{F_{n+2}}
\]
As we'll see, the angular rotation between successive leaf structures is often very close to this angle for Fibonacci (but not, for example, Lucas) phyllotaxis.




\section{Co-prime integers and the B\'ezout relation}

\label{sec:coprime}
Two integers $(m,n)$ are co-prime iff their greatest common divisor is equal to 1, so that for example 4 and 11 are co-prime. We need to be explicit about some edge cases, by noticing that every integer is a divisor of $0$, but the only divisors of $1$ are $1$ and $-1$. Specifically we recognise both of the pairs $(0,1)$ and $(1,n)$ as co-prime, and note that $1$ is co-prime to itself, but $0$ is not, and $(0,n)$ is not co-prime for $n>1$.%
%\footnote{We don't require the integers to be non-negative for this co-primality to make sense, but we avoid situations where this matters.}

\subsection{B\'ezout relations}
The integer pair $(u,v)$ satisfies the B\'ezout relation for the non-negative integer pair $(m,n)$ iff\jNote{The word `iff' is not a typo. It means if and only if, and is also a shibboleth.
If it is bewildering to you that `iff' means logical equivalence and not just implication then you have not been inducted into the kind of mathematical exposition, roughly first-year undergraduate, we use until around section~\ref{sec:ClassifyingSummary}, so you will want to skip to there. On the other hand you can read all of the rest of the book without knowing what a shibboleth is.}
\begin{align}
	|n  u-mv| = 1.
\end{align}
So $(3,4)$ are a B\'ezout pair for $(8,11)$. 
If $u$ and $v$ exist then they are a proof of co-primality: we will see below that $(m,n)$ can satisfy  $ n  u - m v= k$ iff $|k|$ is the greatest common factor of $m$ and $n$. They are not unique because if $(u,v)$ satisfies the B\'ezout relation then so does $(u+km,v+kn)$ for any integer $k$: $(11,15)$ is also a B\'ezout pair for $(8,11)$. We can introduce a range condition by picking a particular $k$ which can be used to enforce $0\leq v< n$, but there is still a further ambiguity because if
$n u- m v  =+1$ provides one solution, then $n(m-u)-m(n-v)=-1$ provides another: because $11\times3-4\times8 =+1$ we can find $11\times 1-4\times 3=-1$. 

\subsection{The winding-number pair}
\label{sec:wnp}
There are different ways to cope with the non-uniqueness of  B\'ezout pairs.
Here we pick out a particular pair, the \textit{winding-number pair}. 
For co-prime integers  $(m,n)$, the winding-number pair is the unique pair  $(u,v)$ which satisfies the B\'ezout relation $|n  u-mv| = 1$ and also
\begin{align}
	0\leq \frac{u+v}{m+n}\leq \frac{1}{2}. \label{eq:wnpFarey}
\end{align}
There are a handful of special cases: the winding-number pair for  $(0,1)$ is by definition $(1,0)$, for $(1,0)$ is $(0,1)$, and for $(1,1)$ is $(1,0)$. 
As we will see below, half of the time the winding-number pair will yield $nu-mv=+1$ and half the time $n u-m v=-1$. We could alternatively have found a unique pair by insisting on a particular choice of sign $nu-mv=+1$, but in this way there is a clear connection to the signs of the $\Delta$s that will pepper Chapter~\ref{ch:cylinder}. Chapter~\ref{ch:cylinder} will also reveal the reason for the name `winding-number pair'. 


\begin{jExercise}
	Compute the winding-number pair for $(m,n)$ for co-prime $m,n$ less than 10. 
\end{jExercise}
\begin{jAnswer} 
	\label{ex:wnp}
	Some winding-number pairs are given in Table~\ref{tab:wnp2}.
	\begin{table}
	\begin{equation*}
		\begin{array}{lllll}
			\hline
			\\
			\jFarey{u}{m}{v}{n}
			&\jFarey{0}{1}{1}{0}&   &  &   \\[2ex]
			\jFarey{ 1}{0}{0}{1} &  \jFarey{1}{1}{0}{1}  &  \jFarey{1}{2}{0}{1}  & \jFarey{1}{3}{0}{1}& \jFarey{1}{4}{0}{1} \\[2ex]
			&  \jFarey{0}{1}{1}{2}&  & \jFarey{1}{3}{1}{2} &  \\
			&  \jFarey{0}{1}{1}{3} & \jFarey{1}{2}{1}{3} &  & \jFarey{1}{4}{1}{3} \\[2ex]
			&  \jFarey{0}{1}{1}{4} &  & \jFarey{1}{3}{1}{4} & \\[2ex]
			&  \jFarey{0}{1}{1}{5} &\jFarey{1}{2}{2}{5} & \jFarey{1}{3}{2}{5} &\jFarey{1}{4}{1}{5} \\[2ex]
			&  \jFarey{0}{1}{1}{6} &  &  &  \\
			&  \jFarey{0}{1}{1}{7} &\jFarey{1}{2}{3}{7}& \jFarey{1}{3}{2}{7} & \jFarey{1}{4}{2}{7}  \\[2ex]
			&  \jFarey{0}{1}{1}{8} &  & \jFarey{1}{3}{3}{8} &  \\[2ex]
			&  \jFarey{0}{1}{1}{9} & \jFarey{1}{2}{4}{9} &  & \jFarey{1}{4}{2}{9}  \\[2ex]
			\hline
		\end{array}
	\end{equation*}
		\caption{Winding number pairs given as Farey intervals $[u/m,v/n]$. For $m$ and $n$ positive and distinct these are all contained in $[0,\jhalf]$ but the natural order of the endpoints varies with the sign of $mv-nu=\pm 1$.}
		\label{tab:wnp2}
	\end{table}
	
\end{jAnswer}



For the small integers in plant spiral counts it is perfectly feasible to compute highest common factors and winding-number pairs by exhaustive search. But nevertheless the rest of this Chapter shows how an algorithmic approach sheds a light on the structure of co-prime pairs and their winding-numbers in a way that has been helpful in the past to mathematicians puzzling over Fibonacci structure. 


\section{Euclid's algorithm}
\label{sec:euclid}
Euclid's algorithm finds the highest common factor of two positive integers by repeatedly subtracting the smaller as many times as we can from the larger to find a new, smaller pair of integers,  stopping when one of them is zero. It is  simple to implement, and tracking the variables in the intermediate steps of the algorithm will allow us to understand connections with continued fractions and structure of the van Iterson diagram of Chapter~\ref{ch:cylinder}.
For example, consider calculating the highest common factor of $4$ and $11$:
\begin{align}
	11 - {\jHeadingColour 2}\times 4 & = 3 
	\\
	4 - {\jHeadingColour 1}\times 3 & = 1\label{eq:411}
	\\
	3 - {\jHeadingColour 3}\times 1 & = 0 
\end{align}
This works by successively answering the question of how many times 4 goes into 11 (ie ${\jHeadingColour 2}$), 3 into 4  (${\jHeadingColour 1}$), and 1 into 3 (${\jHeadingColour 1}$) and generates 
a particular sequence of what we will call  $\jqi={\jHeadingColour 2, 1, 3}$ which shows the co-primality of 4 and 11. Because of the central role of the $\jqi$ they are coloured in red in what follows. It is possible to use this decomposition to compute the winding-number pair, which we can see if we rewrite the algorithm in more formally. 
Given integers $n\geq m>0$  we set $r_{-1}=n$, $r_0=m$ and $i=0$:
\begin{enumerate}
	\item Set an integer $\jqi=\lfloor r_{i-1}/r_i \rfloor $, to non-negatively minimise $r_{i-1}-q r_{i}$ 
	\item  Set  $r_{i+1}=r_{i-1}-\jqi r_{i}$. 
	\item If $r_{i+1}=0$, set $N=i$ and terminate.
	\item Otherwise increment $i$, and repeat.
\end{enumerate}
\begin{theorem}
	Euclid's algorithm terminates with the greatest common factor $GCF(m,n)$:
	\begin{eqnarray}
		r_N =  
		GCF(m,n) 
	\end{eqnarray}
\end{theorem}
\begin{proof}
	The $r_i$ are a strictly decreasing sequence of positive integers and so the algorithm always terminates. Suppose the $GCF$ is $k$. Now $k$ divides $r_0$, $k|r_0$, and the $i$-th step of the iteration preserves the fact that  $k|r_i$,  and so in particular $k|r_N$. Now $r_N|r_{N-1}$ and the iteration step also shows that if $r_N|r_i$ and $r_N|r_{i-1}$ then $r_N|r_{i-2}$, and so following the $r_i$s in reverse order we see $r_N$ divides all of them and divides both $m$ and $n$.  So $r_N$ is a common divisor and so $r_N\leq k$ but since $k|r_N$, $r_N=k$. 
\end{proof}

\subsection{Matrix form of the Euclidean algorithm}
\vnmafig{Ch2EuclideanTree}{Computing the highest common factor of 4 and 11 by successive matrix reductions upwards to the identity matrix. Conversely, the extended tree downwards from the identity matrix, branching by an $E$ or an $ES$ matrix-multiplication at each node after the second, will contain every pair of co-prime integers, in the first column of each matrix, with the corresponding winding-number pair in the second column. 
The $\jqi$s of the Euclidean reduction emerge as the number of $E$s between each $S$.}{1}
%
We can solve the B\'ezout relation by putting  Euclid's algorithm in matrix form. For example
the first reduction of~\eqref{eq:411} is
\begin{align*}
\begin{pmatrix} 11 \\ 4 \end{pmatrix}  &= \begin{pmatrix} 1 & \jqn{2} \\ 0 & 1\end{pmatrix} \begin{pmatrix} 3 \\ 4\end{pmatrix} 
\\
&
= \begin{pmatrix} 1 &1 \\ 0 & 1\end{pmatrix}^{\jqn{2}}  \begin{pmatrix} 0 & 1  \\ 1 & 0  \end{pmatrix} \begin{pmatrix} 4 \\ 3 \end{pmatrix}
\\
&=
E^{\jqn{2}} S \begin{pmatrix} 4 \\ 3 \end{pmatrix}
\end{align*}
where we have defined matrices  $E$ corresponding to a  `Euclidean' reductions and $S$ corresponding to `swap' of the integer pair. Matrix algebra shows $E^\jq$ has a $q$ in the upper-right corner:
\begin{align*}
	E^{\jq} &=  \begin{pmatrix} 1 & \jq \\ 0 & 1\end{pmatrix}
	;
	S =  \begin{pmatrix} 0 & 1  \\ 1 & 0  \end{pmatrix}
	;
	E^{\jq} \cdot S = \begin{pmatrix}\jq & 1  \\ 1 & 0  \end{pmatrix}
\end{align*}
Moreover  $\det E=1$ and $\det S=-1$ and so the matrix of any product of $E$s and $S$s has determinant of modulus 1. 

After we learn the $\jq$ sequence through the Euclidean algorithm we can write the result in matrix form as 
\begin{align*}
	\begin{pmatrix} 11 \\ 4 \end{pmatrix}  &= 
	(E^{\jqn{2}} S )\cdot( E^{\jqn{1}} S ) \cdot (E^{\jqn{3}} S)  \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
\end{align*}
If we apply the same series of transformations to the column vector $(0,1)$ we will obtain a column vector of the form $(v,u)$  so that
\begin{align}
		M_{\jqn{2}\jqn{1}\jqn{3}}= \begin{pmatrix} 11 & v \\ 4 & u \end{pmatrix}   &= 
	(E^{\jqn{2}} S )\cdot( E^{\jqn{1}} S ) \cdot (E^{\jqn{3}} S) 
	 \begin{pmatrix} 1&0  \\ 0&1 \end{pmatrix} 
	 \label{eq:M213}.
\end{align}
This shows that  $u$ and $v$ which satisfy $|4 v-11 u|=1$ and give us a B\'ezout relation, and since $\det E=1$ but $\det S=-1$, the sign of the determinant of $M$ is determined by how many $S$ matrices appear in the product. It also provides a way to calculate $u$ and $v$:
\begin{align*}
	M_{\jqn{2}\jqn{1}\jqn{3}}&=
	 \begin{pmatrix} 2 & 1 \\ 1 & 0 \end{pmatrix}\cdot
 \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}\cdot
	  \begin{pmatrix} 3 & 1 \\ 1 & 0 \end{pmatrix}
	 	 \\
	 &= \begin{pmatrix} 11 & 3 \\ 4 & 1 \end{pmatrix}
% \label{eq:M213value}.
\end{align*}
For a general $m$ and $n$, using the $\jqi$ values from the Euclidean algorithm gives us 
\begin{align}
	M_{\jqn{q_1}\jqn{q_2}\cdots\jqn{q_N}}=\begin{pmatrix} n & v \\ m & u \end{pmatrix}   &= 
	(E^{\jqn{q_1}} S )\cdot( E^{\jqn{q_2}} S ) \cdots  (E^{\jqn{q_N}} S)  \begin{pmatrix} 1&0  \\ 0&1 \end{pmatrix}.
	\label{eq:EuclideanMatrixq}
\end{align}
%Dropping the $\jq$s now, we will 
%\begin{align}
%	M_{nm} &=\begin{pmatrix} n & v \\ m & u \end{pmatrix} 
%	\\
%	\Delta_{nm} &= \det 	M_{nm}
%	\\
%	|\Delta_{nm}| &= 1
% 	\label{eq:EuclideanMatrix}
%\end{align}
In the next section we will show that $(u,v)$ are winding-numbers for $(m,n)$. 


%


\begin{jExercise}
	Show that if $m$ and $n$ have highest common factor $k$ then $u,v$ found in this way give $|nu-mv|=k$.
\end{jExercise}
\begin{jAnswer}
	Multiply~\eqref{eq:EuclideanMatrixq} by $k$
\end{jAnswer}


Looking at the Euclidean algorithm from a broader perspective, it can  be seen as a series of changes of basis for representing integers. The individual $E^{\jqi}$ matrices correspond to  M\"obius transforms that change base at each step, the product matrix is the change of basis between $m,n$ and $k,1$, and the $ |mv - nu|=k$ relationship tells us about how areas are scaled in the different bases. 

\subsection{Farey trees and winding-number pairs}

Thanks to a careful choice of stopping rule for the algorithm, or equivalently because of how we pruned the tree of Figure~\ref{fig:Ch2EuclideanTree} not to bifurcate from the first two nodes, the $(u,v)$ which emerge from the Euclidean algorithm are not just a pair satisfying the B\'ezout relation but they are exactly the winding-number pair.
%
Each matrix in the tree of Figure~\ref{fig:Ch2EuclideanTree} is of the form
\begin{align*}
	\begin{pmatrix} 
		n & v
		\\
		m & u
	\end{pmatrix}
\end{align*}
with $nu-mv=\Delta$ and $|\Delta|=1$. For each matrix below the root, we can form two rationals $u/m$ and $v/n$; for  $\Delta=1$, $u/m>v/n$ while for $\Delta=-1$, $u/m<v/n$ but in either case they form the endpoints of a real interval we will call the Farey interval for the matrix. 
The Farey interval of the integers $m, n, u, v$ is $[u/m,v/n]$ although the endpoints may not be in order. 
The Farey sum of these two rational endpoints, or the Farey sum of the matrix, is $(u+v)/(m+n)$ which is always contained in the Farey interval.
\begin{jExercise}
	Show this.
\end{jExercise}
\begin{jAnswer}
	Compute the difference between the Farey sum and the endpoints: the signs of these and the difference between the endpoints are all controlled by the sign of $\Delta$. 
\end{jAnswer}

Farey intervals for the first few matrices in the tree are shown in Figure~\ref{fig:Ch2GeneratingIntervals}.
\vnmafig{Ch2GeneratingIntervals}{Farey intervals $[u/m,v/n]$ for matrices $\begin{pmatrix}
		n & v\\ u & m
\end{pmatrix}
$ coloured blue if the determinant of the matrix is $+1$ and left white it is $-1$.
}{1}
%
If a matrix has a Farey interval of  $[u/m,v/n]$, then multiplication by $E$ gives a new matrix with a Farey interval of $[u/m,(u+m)/(v+n)]$ and multiplication by $ES$ gives one of  $[v/n,(u+m)/(v+n)]$: the interval splits at the Farey point at each bifurcation. Since the matrix one down from the root has a Farey interval of $[0,\jhalf]$, every matrix below that has its Farey interval within this range, which means that  B\'ezout pair in the second column of each matrix is in fact a winding-number pair.

 Examining the tree also justifies our claim that $m v-nu$ is plus or minus one equally often in the tree (save for the first two nodes), since its sign changes each time there is a multiplication by $ES$ rather than $S$.


\subsection{The Euclidean algorithm for Fibonacci structure pairs}
\label{sec:euclidean}
Figure~\ref{fig:Ch2EuclideanTree} shows that, for example,
\begin{align*}
	\begin{pmatrix} 
	13 & 5 
		\\
		8 & 3
	\end{pmatrix} &= 	(E S)^{{4}} \cdot E^2 S ;
\end{align*}
and, recalling that $F_{7}=13$, we can generalise this to
\begin{align}
	\begin{pmatrix} 
		F_{j+1} & F_{j-1} 
		\\
		F _j & F_{j-2}
	\end{pmatrix} &= 	(E S)^{{j-4}} \cdot E^2 S.
\label{eq:FibonacciMatrix}
\end{align}

\begin{jExercise}
	Prove this.
\end{jExercise}
\begin{jAnswer}  
\begin{align}
E S \begin{pmatrix} 	F_{j+1} & F_{j-1} 	\\	F _j & F_{j-2}\end{pmatrix}
  &= 	\begin{pmatrix} 1 & 1\\1 & 0 \end{pmatrix}
\begin{pmatrix} F_{j+1} & F_{j-1} \\F _j & F_{j-2}\end{pmatrix}
&= 
\begin{pmatrix} 	F_{j+2} & F_{j+1} 	\\	F _{j+2} & F_{j-1}
\end{pmatrix}
\end{align}
\end{jAnswer}
By comparison with the preceding section this shows that the $\jq$s of the Euclidean algorithm for adjacent Fibonacci numbers $(F_{j+1},F_j)$ are a sequence of $\jqn{1}$s of length $j$; alternatively this can be read off from Figure~\ref{fig:Ch2EuclideanTree}.

\begin{jExercise}
	Show that  the winding-number pair for the Fibonacci pair $(m,n)= (F_j,F_{j+1})$ is the pair formed by the two preceding Fibonacci numbers $(u,v)=(F_{j-2},F_{j-1})$.
\end{jExercise}
\begin{jAnswer}  
From \eqref{eq:FibonacciMatrix},
	\begin{align}		 
		\begin{vmatrix} 
		n  & v
			\\
			m & u
			\end{vmatrix}
			= (-1)^{j-1} 
	\end{align}
so $(u,v)$ are a B\'ezout pair for $(m,n)$. Moreover
	\begin{align}		 
(u+v)/(m+n)&= F_j/F_{j+2}
	\end{align}
	which is in $[0,\jhalf]$ and so $(u,v)$ are the winding numbers of equation~\ref{eq:wnpFarey}.
\end{jAnswer}

\subsubsection{Generalised Fibonacci numbers}
Most of the standard results on the algebra of Fibonacci numbers~\cite{koshyFibonacciLucasNumbers2001,dunlapGoldenRatioFibonacci1997,coxeterIntroductionGeometry1989} can be generated using this matrix multiplication formalism. For example
generalised Fibonacci numbers are generated with the  recurrence
\begin{align}
	\label{eq:GeneralisedF}
		F^k_{j+1} &=  F^k_{j-1}+  F^k_{j}, \\
		F^k_1&=1,\\
		F^k_2&=k.
\end{align}
so that Fibonacci numbers have $k=1$ and Lucas numbers $k=3$. By inspecting Figure~\ref{fig:Ch2EuclideanTree}, or by induction, we can see
\begin{align}
	\begin{pmatrix} 
		F^k_{j+1} & F_j 
		\\
		F^k_j & F_{j-1}
	\end{pmatrix} &= 	(E\cdot  S)^{\jqn{j}} \cdot  (E^{\jqn{k}} S) 
\label{eq:GeneralizedFibonacciMatrix}
\end{align}
so that the $\jq$s for an adjacent pair of generalised Fibonacci numbers  $(F^k_{j+1},F^k_j)$ are a sequence of $j-1$ $\jqn{1}$s followed by a single $\jqn{k}$.
By taking the determinant of this relation we get 
\begin{align}
	F^k_j F_j - F^k_{j+1} F_{j-1} &= (-1)^{j-1} \label{eq:fkwinding}
\end{align}
which is a well-known relation 
we will use later to solve $|nu-mv|=1$ when $m$ and $n$ are adjacent generalised Fibonacci numbers.

 The matrix $(E\cdot S)^\jqn{j}$ has determinant of modulus 1 and is invertible and this inverse can be used in~\eqref{eq:GeneralizedFibonacciMatrix} to find another well-known relation:
\begin{align}
	   F^k_{j+1} &=  F_{j-1} + k F_j
\end{align}
it follows from this that for large $j$, 
\begin{align}
	F_j/F^k_{j+1}&=(F_j/F_{j-1}) / (1+k F_j/F_{j-1})
	\\
	&\tends \tau/(1+k\tau)
	,
\end{align} which we will also use later.

\section{Continued fractions}

If we divide each line of the Euclidean algorithm example above by $r_i$ we get
\begin{align}
	\frac{11}{4} - {\jHeadingColour 2} & = \frac{3}{4}
	\\
	\frac{4}{3} - {\jHeadingColour 1} & = \frac{1}{3}
	\\
	\frac{3}{1} - {\jHeadingColour 3} & = 0 
\end{align}
In each case the right hand side fraction is the inverse of the first fraction on the next line and we can solve  in reverse order to get
\begin{align}
	\frac{1}{3} &=  \frac{1}{\jHeadingColour 3}
	\\
	\frac{3}{4} &=  \frac{1}{{\jHeadingColour 1}+ \frac{1}{\jHeadingColour 3}}
	\\
	\frac{11}{4} &=  {\jHeadingColour 2}+
		\frac{1}{{\jHeadingColour 1}+ \frac{1}{\jHeadingColour 3}}
\end{align}
So there is a close link between the Euclidean algorithm and the construction of continued fractions. 
The continued fraction
generated by the finite sequence $\jqix{0}\ldots \jqix{N} $ is by definition
\begin{align}
	[\jqix{0},\ldots  \jqix{N}] &= \jqix{0} +\cfrac{1}{\jqix{1}+\cdots \cfrac{\cdots}{\jqix{{N-1}}+\cfrac{1}{\jqix{N}}}}
\end{align}
When representing a continued fraction less than 1, $\jqix{0}$ will be zero, but otherwise typically the $\jqi$ are strictly positive integers. We can usefully relax this rule for the last coefficient:
\begin{align}
	\frac{11}{4} &=  	[\jqn{2},\jqn{1},\jqn{3}]
	\\
&= 	[\jqn{2},\jqn{1}+1/\jqn{3}].
\end{align}
The reason we have used the same label $\jq$ as in the Euclidean algorithm is that the integer $\jq_i$s that the Euclidean algorithm generates for the hcf of $m$ and $n$ are exactly the continued fraction coefficients of $n/m$. Specifically, to compute the continued fraction coefficients $\jqix{0}\ldots \jqix{N} $ of a real $d$ we set 
$\rho_{-1}=d$, $\rho_{0}=1$ and $i=0$ and then
\begin{enumerate}
	\item Set an integer $\jqi=\lfloor \rho_{i-1}/\rho_{i} \rfloor$
	\item Set $\rho_{i+1} = \rho_{i-1} - \jqi \rho_{i}$. 
	\item If $\rho_{i+1} =0$, set $N=i$ and terminate
	\item Otherwise increment $i$ and repeat
\end{enumerate}
This is  the same as Euclid's algorithm but for the scaled sequence member $\rho_i=r_i/r_{i+1}$. It will terminate if $d$ is rational $n/m$, because Euclid's algorithm does in that case, but it will not if $d$ is irrational. In either case the intermediate continued fractions generated at each stage represent increasingly good approximations to $d$. 

There is a large literature on continued fractions. Fowler~\cite{fowlerMathematicsPlatoAcademy1999} combines the basic results with a relevant historical perspective while Berger~\cite{bergerGeometryRevealedJacob2010} adds an informative geometric view. 

\subsection{Continued fractions and M\"obius maps}
Using the continued-fraction representation, given a set of $q$s we can define a function of $z$ as
\begin{align}
	f_{\jqix{0}\ldots \jqix{i}}(z) &= [\jqix{0}\ldots \jqix{i}  , z] 
\end{align}
Taking coefficients from in our running example we  have 
\begin{align}
f_{\jqn{3}}&=  \jqn{3} + \frac{1}{z} = \frac{3 z+1}{z+0} 
\\
f_{\jqn{1},\jqn{3}}  &=  \jqn{1} + \frac{1}{\jqn{3}+1/z} = \frac{4 z+1}{3z+1} \label{eq:fq}
\\ 
f_{\jqn{2},\jqn{1},\jqn{3}}  &=  \jqn{2} + \frac{1}{\jqn{1}+\frac{1}{
		\jqn{3}+1/z}} = \frac{11 z+3}{4z+1} \label{eq:frac411}.
\end{align}
where we recognise the coefficients of the matrix $M_{\jqn{2},\jqn{1},\jqn{3}}$ of equation~\ref{eq:M213} arising from the Euclidean algorithm for 11 and 4. Clearly this is not a co-incidence, and by analogy with the previous sections we can expect that $f$ can be constructed by repeated function compositions moving us down the tree of Figure~\ref{fig:Ch2EuclideanTree}. 
Indeed since $	f_{\jqix{i}}  =  \jqix{i} +1/{z}  $, the last two can be written as
\begin{align}	
	f_{\jqn{1},\jqn{3}}  &=  	f_{\jqn{1}}(	f_{\jqn{3}}(z)) = 	f_{\jqn{1}}\circ 	f_{\jqn{3}}
	\\	f_{\jqn{2},\jqn{1},\jqn{3}}  &=
	%  	f_{\jqn{2}}(	f_{\jqn{1}}(		f_{\jqn{3}}(z)))) =
	 f_{\jqn{2}}\circ 	f_{\jqn{1}} \circ 	f_{\jqn{3}}
\end{align}
and in general
\begin{align}
	f_{\jqix{0}\jqix{1}\cdots\jqix{N}} &= 	f_{\jqix{0}}\circ f_{\jqix{1}}\cdots\circ f_{\jqix{N}}
\end{align}
Each of the $f$ constructed in this way is a \textit{M\"obius map}.

\subsection{M\"obius functions}
\label{sec:moebiusdef}
M\"obius maps have the form\jNote{Poincar\'e called these Fuchsian functions and they have variously been called automorphic or Hilbert modular functions, affine transforms or fractional linear transformations.  I follow the authority of Wikipedia, partly because as a native English reader I see an umlaut as conferring scientific respectability.}
\begin{align}	f(z) &=  \frac{a z +b}{c z+ d},
\end{align}
and are associated with a coefficient matrix
\begin{align}
	M(f) &=
	\begin{bmatrix}
		a & b \\ c & d	\end{bmatrix}.
\end{align}
It can be verified directly that the composition of two M\"obius maps is a M\"obius map, and that the coefficient matrix of the composition is the product of the coefficient matrices:
\begin{align}
	M(f_1 \circ f_2) &= M(f_1 ) \cdot M( f_2)
\end{align}
One way to see this is to note that 
\begin{equation}
	f\left(\frac{z_1}{z_2}\right) =\frac{w_1}{w_2}  \mbox{ where } 	\begin{pmatrix}
		w_1 \\ w_2 
	\end{pmatrix} = 
	\begin{pmatrix}
		a & b \\ c & d
	\end{pmatrix} 
	\begin{pmatrix}
		z_1 \\ z_2
	\end{pmatrix}
\end{equation}.

Since the coefficient matrices of the individual  functions in~\eqref{eq:fq} are
\begin{align}
	M(f_\jqix{i})  &= M\left(\frac{q z+1}{z+0}\right)= \begin{pmatrix}
		q & 1 \\ 1 & 0
	\end{pmatrix}=  E^{\jqix{i}}\cdot S,
\end{align}
then the continued fraction function $	f_{\jqix{1}\jqix{2}\cdots\jqix{N}}$ is a M\"obius function with coefficient matrix 
\begin{align}
	M(f_{\jqix{1}\jqix{2}\cdots\jqix{N}})  &=	\begin{pmatrix} 
		n & v
		\\
		m & u
	\end{pmatrix}
\end{align}
exactly as in~\eqref{eq:EuclideanMatrixq}. This allows us to convert between a continued fraction formulation and M\"obius one:
\begin{align}
	f_{\jqix{0}\ldots \jqix{N}}(z) &=  [\jqix{0},\ldots ,\jqix{N}  , z]
	= \frac{nz+v}{mz+u} 
\end{align}
showing that~\eqref{eq:frac411} holds true in general. 

If $z$ is a complex variable, then because $f(z)=z+b$, $f(z)=a z$, and $f(z)=1/z$  represent translation, scaling, and inversion in the unit circle,  M\"obius maps correspond to transformations of the complex plane generated by these geometric tranformations.  In  our applications of M\"obius maps the coefficient matrix will always have integer entries and moreover have determinant $mv-nu=\pm 1$. Because every such matrix is invertible in integers the maps form a group which I call the modular group.%
\footnote{If Wikipedia remains the authority, then the modular group is instead the group of matrices with integer entries and determinant $+1$, and the group with determinants $\pm 1$ is  $PSL(2,\jZ)$; but the same authority also says this is called $SL(2,\jZ)$ by some authors.}
	 A comprehensive treatment of M\"obius transformations is Ford's \textit{Automorphic Functions}~\cite{fordAutomorphicFunctions1951}, but they reappear in many branches of modern mathematics. 

We don't rely on, but later Chapters will partially rediscover, some well known properties of the modular group. In the language of hyperbolic geometry, when the upper complex half-plane is given the hyperbolic metric, its geodesics are semi-circles (including vertical lines) on the horizontal axis, and the modular group is the symmetry group of these geodesics: $f$ will map axis semi-circles to axis semi-circles. 

A M\"obius map  $f:\jC\rightarrow\jC$ is a function on the complex plane; it's unhelpful to think of it as a map on the Euclidean plane $\jR^2\rightarrow\jR^2$.  The reason the latter is unhelpful is that, although it has a matrix representation $M(f)$,  $f$ is not a linear map on these real vectors. A 2x2 matrix normally represents such a linear transformation which allows rotation, scaling and shear; here the same number of parameters represent a transformation allowing rotation, scaling and translation. 


